{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/data-hackers/tutorial-para-iniciantes-web-scraping-em-python-bb71778ed40c\n",
    "!pip3 install requests\n",
    "!pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/reinaldonani/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get search url\n",
    "url = 'https://safras.com.br/eng/agribusiness/'\n",
    "response = get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create soup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating individual containers, on each one there's information about one subject\n",
    "main_title_h3 = soup.findAll(class_= 'td-module-meta-info')\n",
    "print(\"all---   \",main_title_h3)\n",
    "len_titles = len(main_title_h3)\n",
    "print(\"len---   \", len_titles)\n",
    "print(\"prettify() ---   \",main_title_h3[0].prettify())\n",
    "print(\"1st---   \",main_title_h3[0].a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty list\n",
    "title_text = []\n",
    "href_link = []\n",
    "date_content = []\n",
    "\n",
    "print(title_text)\n",
    "print(href_link)\n",
    "print(date_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-10\n",
      "2023-12-03\n"
     ]
    }
   ],
   "source": [
    "import datetime as DT\n",
    "today = DT.date.today()\n",
    "print(today)\n",
    "week_ago = today - DT.timedelta(days=7)\n",
    "print(week_ago)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argentina has normal weather and expectations about the new administration for corn\n",
      "https://safras.com.br/eng/argentina-has-normal-weather-and-expectations-about-the-new-administration-for-corn/\n",
      "2023-12-05T15:24:31-03:00\n",
      "--------\n",
      "Soybean planting advances at a better pace in Brazil\n",
      "https://safras.com.br/eng/soybean-planting-advances-at-a-better-pace-in-brazil/\n",
      "2023-12-05T11:41:15-03:00\n",
      "2023-12-03\n",
      "<class 'datetime.date'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "time data '2023-12-05T11:41:15-03:00' does not match format '%Y%m%d'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Applications/3_development/py-scraping/test.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     xxx \u001b[39m=\u001b[39m all_title[item]\u001b[39m.\u001b[39mdiv\u001b[39m.\u001b[39mfind(class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtd-post-date\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtime\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m#print(all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\"))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39m#print(type(all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\")))\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mprint\u001b[39m(DT\u001b[39m.\u001b[39;49mdatetime\u001b[39m.\u001b[39;49mstrptime(xxx, \u001b[39m\"\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mY\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39mdate())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m#    print(week_ago > xxx)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Applications/3_development/py-scraping/test.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m--------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/_strptime.py:568\u001b[0m, in \u001b[0;36m_strptime_datetime\u001b[0;34m(cls, data_string, format)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_strptime_datetime\u001b[39m(\u001b[39mcls\u001b[39m, data_string, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m%a\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mb \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS \u001b[39m\u001b[39m%\u001b[39m\u001b[39mY\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    566\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return a class cls instance based on the input string and the\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39m    format string.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m     tt, fraction, gmtoff_fraction \u001b[39m=\u001b[39m _strptime(data_string, \u001b[39mformat\u001b[39;49m)\n\u001b[1;32m    569\u001b[0m     tzname, gmtoff \u001b[39m=\u001b[39m tt[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m:]\n\u001b[1;32m    570\u001b[0m     args \u001b[39m=\u001b[39m tt[:\u001b[39m6\u001b[39m] \u001b[39m+\u001b[39m (fraction,)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/_strptime.py:349\u001b[0m, in \u001b[0;36m_strptime\u001b[0;34m(data_string, format)\u001b[0m\n\u001b[1;32m    347\u001b[0m found \u001b[39m=\u001b[39m format_regex\u001b[39m.\u001b[39mmatch(data_string)\n\u001b[1;32m    348\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m found:\n\u001b[0;32m--> 349\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtime data \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m does not match format \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    350\u001b[0m                      (data_string, \u001b[39mformat\u001b[39m))\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data_string) \u001b[39m!=\u001b[39m found\u001b[39m.\u001b[39mend():\n\u001b[1;32m    352\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39munconverted data remains: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m    353\u001b[0m                       data_string[found\u001b[39m.\u001b[39mend():])\n",
      "\u001b[0;31mValueError\u001b[0m: time data '2023-12-05T11:41:15-03:00' does not match format '%Y%m%d'"
     ]
    }
   ],
   "source": [
    "for page in np.arange(1,2): # to iterate over the pages and create the conteiners\n",
    "#  url = 'https://www.hostelworld.com/hostels/Berlin?page=' + str(page)\n",
    "  response = get(url)\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "  main_title = soup.findAll(class_= 'td-module-meta-info')\n",
    "  all_title = soup.findAll(class_= 'item-details')\n",
    "  print(main_title_a[0].h3.a.text)\n",
    "  print(main_title_a[0].h3.a.get(\"href\"))\n",
    "  print(main_title_a[0].span.find(class_=\"td-post-date\").time.get(\"datetime\"))\n",
    " \n",
    "  print(\"--------\")\n",
    "\n",
    "  for item in range(len(all_title)): # to iterate over the results on each page\n",
    "    print(all_title[item].h3.a.text)\n",
    "    print(all_title[item].h3.a.get(\"href\"))\n",
    "    print(all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\"))\n",
    "    \n",
    "    print(week_ago)\n",
    "    print(type(week_ago)) \n",
    "    xxx = all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\")\n",
    "    #print(all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\"))\n",
    "    #print(type(all_title[item].div.find(class_=\"td-post-date\").time.get(\"datetime\")))\n",
    "    print(DT.datetime.strptime(xxx, \"%Y%m%d\").date())\n",
    "#    print(week_ago > xxx)\n",
    "    \n",
    "    print(\"--------\")\n",
    "    #print(main_title[item].h3.a.text)\n",
    "    #print(main_title[item].h3.a.get('href'))\n",
    "    #print(main_title[item].span.find(class_=\"td-post-date\").get('datetime'))\n",
    "    #title_text.append(main_title[item].h3.a.text)\n",
    "    #href_link.append(main_title[item].h3.a.get('href'))\n",
    "    #hostel_distance.append(holstel_containers[item].find(class_= \"addressline\").text[12:18].replace('k','').replace('m','').strip())\n",
    "    #hostel_ratings.append(holstel_containers[item].find(class_='hwta-rating-score').text.replace('\\n', '').strip())\n",
    "    #hostel_reviews.append(holstel_containers[item].find(class_=\"hwta-rating-counter\").text.replace('\\n', '').strip())\n",
    "    #hostel_prices.append(holstel_containers[item].find(class_= \"price\").text.replace('\\n', '').strip()[3:])                          \n",
    "  time.sleep(2) # this is used to not push too hard on the website\n",
    "\n",
    "#print(title_text)\n",
    "#print(href_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_title = pd.DataFrame({\n",
    "    \"title_text\": title_text,\n",
    "    \"href_link\": href_link\n",
    "})\n",
    "\n",
    "print(group_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
